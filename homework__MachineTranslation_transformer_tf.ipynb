{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a0086f61",
      "metadata": {
        "id": "a0086f61"
      },
      "source": [
        "# Задание 1.\n",
        "\n",
        "Нужно обучить трансформер на этом же или на другом корпусе (можно взять другую языковую пару с того же сайте) и оценивать его на всей тестовой выборке (а не на 10 примерах как сделал я). Чтобы получить 2 доп балла вам нужно будет придумать как оптимизировать функцию translate. Подсказка: модель может предсказывать батчами."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e3b0ea3c",
      "metadata": {
        "id": "e3b0ea3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0aa10c5f-03cb-4a1b-e1b3-5667b894358d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "unzip is already the newest version (6.0-25ubuntu1.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 15 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!apt-get install unzip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "d650e9eb",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d650e9eb",
        "outputId": "67788cab-b11d-4246-e8ca-cdd5deb31da1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tokenizers\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post5.tar.gz (3.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Building wheels for collected packages: sklearn\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0.post5-py3-none-any.whl size=2950 sha256=215d7e7c1f9d62c67d86b89127e65269a1c1e8c159a99ff6a5f9b2ebb5b9320e\n",
            "  Stored in directory: /root/.cache/pip/wheels/38/1f/8d/4f812c590e074c1e928f5cec67bf5053b71f38e2648739403a\n",
            "Successfully built sklearn\n",
            "Installing collected packages: tokenizers, sklearn\n",
            "Successfully installed sklearn-0.0.post5 tokenizers-0.13.3\n"
          ]
        }
      ],
      "source": [
        "!pip install tokenizers matplotlib sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ac85a206",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac85a206",
        "outputId": "5fb235a3-5983-440c-c4c0-6fc3873c1d96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting jedi==0.17.2\n",
            "  Downloading jedi-0.17.2-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting parso<0.8.0,>=0.7.0 (from jedi==0.17.2)\n",
            "  Downloading parso-0.7.1-py2.py3-none-any.whl (109 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.5/109.5 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: parso, jedi\n",
            "  Attempting uninstall: parso\n",
            "    Found existing installation: parso 0.8.3\n",
            "    Uninstalling parso-0.8.3:\n",
            "      Successfully uninstalled parso-0.8.3\n",
            "Successfully installed jedi-0.17.2 parso-0.7.1\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade jedi==0.17.2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tokenizers"
      ],
      "metadata": {
        "id": "iCLqLoLkdang",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bf31667-4da1-41a5-a1e6-7a6d6a798c2d"
      },
      "id": "iCLqLoLkdang",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.13.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "947b3313",
      "metadata": {
        "id": "947b3313"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tokenizers import BertWordPieceTokenizer\n",
        "\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import WordPiece\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "from tokenizers import normalizers\n",
        "from tokenizers.normalizers import Lowercase\n",
        "from tokenizers.trainers import WordPieceTrainer\n",
        "from tokenizers import decoders\n",
        "\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
        "from string import punctuation\n",
        "from collections import Counter\n",
        "from IPython.display import Image\n",
        "from IPython.core.display import HTML\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "508e8ae0",
      "metadata": {
        "id": "508e8ae0"
      },
      "source": [
        "Данные взяты вот отсюда - https://opus.nlpl.eu/opus-100.php (раздел с отдельными языковыми парами)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-train.ru\n",
        "!wget https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-train.en\n",
        "!wget https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-test.ru\n",
        "!wget https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-test.en"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvUX7tdtc5pZ",
        "outputId": "ff5c1966-a5b5-4d0b-a098-2a45f678fe99"
      },
      "id": "kvUX7tdtc5pZ",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-19 20:25:34--  https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-train.ru\n",
            "Resolving data.statmt.org (data.statmt.org)... 129.215.197.184\n",
            "Connecting to data.statmt.org (data.statmt.org)|129.215.197.184|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 121340806 (116M)\n",
            "Saving to: ‘opus.en-ru-train.ru’\n",
            "\n",
            "opus.en-ru-train.ru 100%[===================>] 115.72M  28.2MB/s    in 5.1s    \n",
            "\n",
            "2023-06-19 20:25:40 (22.6 MB/s) - ‘opus.en-ru-train.ru’ saved [121340806/121340806]\n",
            "\n",
            "--2023-06-19 20:25:40--  https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-train.en\n",
            "Resolving data.statmt.org (data.statmt.org)... 129.215.197.184\n",
            "Connecting to data.statmt.org (data.statmt.org)|129.215.197.184|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 67760131 (65M)\n",
            "Saving to: ‘opus.en-ru-train.en’\n",
            "\n",
            "opus.en-ru-train.en 100%[===================>]  64.62M  22.0MB/s    in 2.9s    \n",
            "\n",
            "2023-06-19 20:25:44 (22.0 MB/s) - ‘opus.en-ru-train.en’ saved [67760131/67760131]\n",
            "\n",
            "--2023-06-19 20:25:44--  https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-test.ru\n",
            "Resolving data.statmt.org (data.statmt.org)... 129.215.197.184\n",
            "Connecting to data.statmt.org (data.statmt.org)|129.215.197.184|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 305669 (299K)\n",
            "Saving to: ‘opus.en-ru-test.ru’\n",
            "\n",
            "opus.en-ru-test.ru  100%[===================>] 298.50K   706KB/s    in 0.4s    \n",
            "\n",
            "2023-06-19 20:25:44 (706 KB/s) - ‘opus.en-ru-test.ru’ saved [305669/305669]\n",
            "\n",
            "--2023-06-19 20:25:44--  https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-test.en\n",
            "Resolving data.statmt.org (data.statmt.org)... 129.215.197.184\n",
            "Connecting to data.statmt.org (data.statmt.org)|129.215.197.184|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 173307 (169K)\n",
            "Saving to: ‘opus.en-ru-test.en’\n",
            "\n",
            "opus.en-ru-test.en  100%[===================>] 169.25K   555KB/s    in 0.3s    \n",
            "\n",
            "2023-06-19 20:25:45 (555 KB/s) - ‘opus.en-ru-test.en’ saved [173307/173307]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "e110ff04",
      "metadata": {
        "id": "e110ff04"
      },
      "outputs": [],
      "source": [
        "en_sents = open('opus.en-ru-train.en').read().lower().splitlines()\n",
        "ru_sents = open('opus.en-ru-train.ru').read().lower().splitlines()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35b8fae3",
      "metadata": {
        "id": "35b8fae3"
      },
      "source": [
        "Пример перевода с английского на русский"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "0eb9b498",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eb9b498",
        "outputId": "b3063597-2f24-4a17-d0a4-a065611f2a78"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('so what are you thinking?', 'ну и что ты думаешь?')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "en_sents[-1], ru_sents[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "0be060a4",
      "metadata": {
        "id": "0be060a4"
      },
      "outputs": [],
      "source": [
        "tokenizer_en = Tokenizer(WordPiece(), )\n",
        "tokenizer_en.normalizer = normalizers.Sequence([Lowercase()])\n",
        "tokenizer_en.pre_tokenizer = Whitespace()\n",
        "\n",
        "trainer_en = WordPieceTrainer(\n",
        "          vocab_size=30000, special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\"])\n",
        "tokenizer_en.train(files=[\"opus.en-ru-train.en\"], trainer=trainer_en )\n",
        "\n",
        "tokenizer_ru = Tokenizer(WordPiece(), )\n",
        "tokenizer_ru.normalizer = normalizers.Sequence([Lowercase()])\n",
        "tokenizer_ru.pre_tokenizer = Whitespace()\n",
        "\n",
        "trainer_ru = WordPieceTrainer(\n",
        "          vocab_size=30000, special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\"])\n",
        "tokenizer_ru.train(files=[\"opus.en-ru-train.ru\"], trainer=trainer_ru )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "' '.join(tokenizer_ru.encode('Пример текста с редким словом').tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "EVuGuhHg3-Tq",
        "outputId": "df2084ee-8dfe-4064-ce2b-dc9bdfd22270"
      },
      "id": "EVuGuhHg3-Tq",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'пример текста с ред ##ким словом'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_en.decoder = decoders.WordPiece()\n",
        "tokenizer_ru.decoder = decoders.WordPiece()"
      ],
      "metadata": {
        "id": "xWX3xnMUzbdt"
      },
      "id": "xWX3xnMUzbdt",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "496d0ea7",
      "metadata": {
        "id": "496d0ea7"
      },
      "outputs": [],
      "source": [
        "tokenizer_en.save('tokenizer_en')\n",
        "tokenizer_ru.save('tokenizer_ru')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "f4661964",
      "metadata": {
        "id": "f4661964"
      },
      "outputs": [],
      "source": [
        "tokenizer_en = Tokenizer.from_file(\"tokenizer_en\")\n",
        "tokenizer_ru = Tokenizer.from_file(\"tokenizer_ru\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "dc003758",
      "metadata": {
        "id": "dc003758"
      },
      "outputs": [],
      "source": [
        "def encode(text, tokenizer, target=False):\n",
        "    return [tokenizer.token_to_id('[CLS]')] + tokenizer.encode(text).ids + [tokenizer.token_to_id('[SEP]')]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "7fc2dae1",
      "metadata": {
        "id": "7fc2dae1"
      },
      "outputs": [],
      "source": [
        "X_en = [encode(t, tokenizer_en) for t in en_sents]\n",
        "X_ru = [encode(t, tokenizer_ru, target=True) for t in ru_sents]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "5cc0a376",
      "metadata": {
        "id": "5cc0a376"
      },
      "outputs": [],
      "source": [
        "max_len_en, max_len_ru = 20, 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "3f4f31fa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f4f31fa",
        "outputId": "319ea14b-45b1-454a-e1d2-61ae6c15f9c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "PAD_IDX = tokenizer_ru.token_to_id('[PAD]')\n",
        "PAD_IDX"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_en.token_to_id('[PAD]')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7yDKRVP7SC5",
        "outputId": "8c9f1c90-11f1-424d-ae2b-650d05d03c02"
      },
      "id": "F7yDKRVP7SC5",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "49ae735e",
      "metadata": {
        "id": "49ae735e"
      },
      "outputs": [],
      "source": [
        "X_en = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "              X_en, maxlen=max_len_en, padding='post', value=tokenizer_en.token_to_id('[PAD]'))\n",
        "\n",
        "X_ru_out = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "              [x[1:] for x in X_ru], maxlen=max_len_ru-1, padding='post',\n",
        "              value=tokenizer_en.token_to_id('[PAD]'))\n",
        "\n",
        "X_ru_dec = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "              [x[:-1] for x in X_ru], maxlen=max_len_ru-1,\n",
        "              padding='post', value=tokenizer_ru.token_to_id('[PAD]'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "824dcb29",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "824dcb29",
        "outputId": "0de22182-6e01-4f5f-cd20-a739739dde24"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1000000, 20), (1000000, 19))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "X_en.shape, X_ru_out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "25fa5f05",
      "metadata": {
        "id": "25fa5f05"
      },
      "outputs": [],
      "source": [
        "X_en_train, X_en_valid, X_ru_dec_train, X_ru_dec_valid, X_ru_out_train, X_ru_out_valid = train_test_split(X_en,\n",
        "                                                                                                      X_ru_dec,\n",
        "                                                                                                      X_ru_out,\n",
        "                                                                                                      test_size=0.05)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f045ac37",
      "metadata": {
        "id": "f045ac37"
      },
      "source": [
        "# Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "656be820",
      "metadata": {
        "id": "656be820"
      },
      "outputs": [],
      "source": [
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "    \"\"\"Calculate the attention weights. \"\"\"\n",
        "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "\n",
        "    # scale matmul_qk\n",
        "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "    logits = matmul_qk / tf.math.sqrt(depth)\n",
        "\n",
        "    # add the mask to zero out padding tokens\n",
        "    if mask is not None:\n",
        "        logits += (mask * -1e9)\n",
        "\n",
        "    # softmax is normalized on the last axis (seq_len_k)\n",
        "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
        "\n",
        "    output = tf.matmul(attention_weights, value)\n",
        "\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "f4b51870",
      "metadata": {
        "id": "f4b51870"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
        "        super(MultiHeadAttention, self).__init__(name=name)\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "\n",
        "        assert d_model % self.num_heads == 0\n",
        "\n",
        "        self.depth = d_model // self.num_heads\n",
        "\n",
        "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
        "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
        "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "    def split_heads(self, inputs, batch_size):\n",
        "        inputs = tf.reshape(\n",
        "            inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
        "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
        "            'value'], inputs['mask']\n",
        "        batch_size = tf.shape(query)[0]\n",
        "\n",
        "        # linear layers\n",
        "        query = self.query_dense(query)\n",
        "        key = self.key_dense(key)\n",
        "        value = self.value_dense(value)\n",
        "\n",
        "        # split heads\n",
        "        query = self.split_heads(query, batch_size)\n",
        "        key = self.split_heads(key, batch_size)\n",
        "        value = self.split_heads(value, batch_size)\n",
        "\n",
        "        # scaled dot-product attention\n",
        "        scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
        "\n",
        "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "        # concatenation of heads\n",
        "        concat_attention = tf.reshape(scaled_attention,\n",
        "                                      (batch_size, -1, self.d_model))\n",
        "\n",
        "        # final linear layer\n",
        "        outputs = self.dense(concat_attention)\n",
        "\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "5c48cea2",
      "metadata": {
        "id": "5c48cea2"
      },
      "outputs": [],
      "source": [
        "def create_padding_mask(x):\n",
        "    mask = tf.cast(tf.math.equal(x, PAD_IDX), tf.float32)\n",
        "    # (batch_size, 1, 1, sequence length)\n",
        "    return mask[:, tf.newaxis, tf.newaxis, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "21c0c899",
      "metadata": {
        "id": "21c0c899"
      },
      "outputs": [],
      "source": [
        "def create_look_ahead_mask(x):\n",
        "    seq_len = tf.shape(x)[1]\n",
        "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "    padding_mask = create_padding_mask(x)\n",
        "    return tf.maximum(look_ahead_mask, padding_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "e120bbe5",
      "metadata": {
        "id": "e120bbe5"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, position, d_model):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "\n",
        "    def get_angles(self, position, i, d_model):\n",
        "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "        return position * angles\n",
        "\n",
        "    def positional_encoding(self, position, d_model):\n",
        "        angle_rads = self.get_angles(\n",
        "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "        d_model=d_model)\n",
        "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "        pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
        "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "        return tf.cast(pos_encoding, tf.float32)\n",
        "\n",
        "    def call(self, inputs):\n",
        "\n",
        "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "68472627",
      "metadata": {
        "id": "68472627"
      },
      "outputs": [],
      "source": [
        "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
        "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "    attention = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention\")({\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
        "    attention = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(inputs + attention)\n",
        "\n",
        "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
        "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "    outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "    return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "89dcc42e",
      "metadata": {
        "id": "89dcc42e"
      },
      "outputs": [],
      "source": [
        "def encoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            max_len,\n",
        "            name=\"encoder\"):\n",
        "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "    embeddings = PositionalEncoding(max_len, d_model)(embeddings)\n",
        "\n",
        "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "    for i in range(num_layers):\n",
        "        outputs = encoder_layer(\n",
        "            units=units,\n",
        "            d_model=d_model,\n",
        "            num_heads=num_heads,\n",
        "            dropout=dropout,\n",
        "            name=\"encoder_layer_{}\".format(i),\n",
        "        )([outputs, padding_mask])\n",
        "\n",
        "    return tf.keras.Model(inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "a2f90e7c",
      "metadata": {
        "id": "a2f90e7c"
      },
      "outputs": [],
      "source": [
        "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
        "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "    look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
        "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "    attention1 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': look_ahead_mask\n",
        "      })\n",
        "    attention1 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention1 + inputs)\n",
        "\n",
        "    attention2 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
        "          'query': attention1,\n",
        "          'key': enc_outputs,\n",
        "          'value': enc_outputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
        "    attention2 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention2 + attention1)\n",
        "\n",
        "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
        "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "    outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(outputs + attention2)\n",
        "\n",
        "    return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "8e9f89b8",
      "metadata": {
        "id": "8e9f89b8"
      },
      "outputs": [],
      "source": [
        "def decoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            max_len,\n",
        "            name='decoder'):\n",
        "    inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
        "    enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
        "    look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name='look_ahead_mask')\n",
        "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "    embeddings = PositionalEncoding(max_len, d_model)(embeddings)\n",
        "\n",
        "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "    for i in range(num_layers):\n",
        "        outputs = decoder_layer(\n",
        "            units=units,\n",
        "            d_model=d_model,\n",
        "            num_heads=num_heads,\n",
        "            dropout=dropout,\n",
        "            name='decoder_layer_{}'.format(i),\n",
        "        )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
        "\n",
        "    return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "e356741b",
      "metadata": {
        "id": "e356741b"
      },
      "outputs": [],
      "source": [
        "def transformer(vocab_size,\n",
        "                num_layers,\n",
        "                units,\n",
        "                d_model,\n",
        "                num_heads,\n",
        "                dropout,\n",
        "                max_len,\n",
        "                name=\"transformer\"):\n",
        "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
        "\n",
        "    enc_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='enc_padding_mask')(inputs)\n",
        "    # mask the future tokens for decoder inputs at the 1st attention block\n",
        "    look_ahead_mask = tf.keras.layers.Lambda(\n",
        "      create_look_ahead_mask,\n",
        "      output_shape=(1, None, None),\n",
        "      name='look_ahead_mask')(dec_inputs)\n",
        "    # mask the encoder outputs for the 2nd attention block\n",
        "    dec_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='dec_padding_mask')(inputs)\n",
        "\n",
        "    enc_outputs = encoder(\n",
        "      vocab_size=vocab_size[0],\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "      max_len=max_len[0],\n",
        "    )(inputs=[inputs, enc_padding_mask])\n",
        "\n",
        "    dec_outputs = decoder(\n",
        "      vocab_size=vocab_size[1],\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "      max_len=max_len[1],\n",
        "    )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
        "\n",
        "    outputs = tf.keras.layers.Dense(units=vocab_size[1], name=\"outputs\")(dec_outputs)\n",
        "\n",
        "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "6c35ce0f",
      "metadata": {
        "id": "6c35ce0f"
      },
      "outputs": [],
      "source": [
        "L  = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=True, reduction='none',)\n",
        "\n",
        "def loss_function(y_true, y_pred):\n",
        "    loss = L(y_true, y_pred)\n",
        "\n",
        "    mask = tf.cast(tf.not_equal(y_true, PAD_IDX), tf.float32)\n",
        "    loss = tf.multiply(loss, mask)\n",
        "\n",
        "    return tf.reduce_mean(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "747835a8",
      "metadata": {
        "id": "747835a8"
      },
      "outputs": [],
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "542fcc43",
      "metadata": {
        "id": "542fcc43"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "NUM_LAYERS = 2\n",
        "D_MODEL = 256\n",
        "NUM_HEADS = 8\n",
        "UNITS = 512\n",
        "DROPOUT = 0.1\n",
        "\n",
        "\n",
        "\n",
        "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
        "with mirrored_strategy.scope():\n",
        "    model = transformer(\n",
        "        vocab_size=(tokenizer_en.get_vocab_size(),tokenizer_ru.get_vocab_size()),\n",
        "        num_layers=NUM_LAYERS,\n",
        "        units=UNITS,\n",
        "        d_model=D_MODEL,\n",
        "        num_heads=NUM_HEADS,\n",
        "        dropout=DROPOUT,\n",
        "        max_len=[max_len_en, max_len_ru])\n",
        "\n",
        "#     learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(\n",
        "        0.001, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "    def accuracy(y_true, y_pred):\n",
        "#         y_true = tf.reshape(y_true, shape=(-1, max_len_ru - 1))\n",
        "        return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "\n",
        "    model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n",
        "    checkpoint = tf.keras.callbacks.ModelCheckpoint('model_ruen',\n",
        "                                                monitor='val_loss',\n",
        "                                                verbose=1,\n",
        "                                            save_weights_only=True,\n",
        "                                            save_best_only=True,\n",
        "                                            mode='min',\n",
        "                                            save_freq='epoch')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "308a8e81",
      "metadata": {
        "id": "308a8e81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcc6b2ef-7172-4fef-90ee-df30ea034f0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1900/1900 [==============================] - ETA: 0s - loss: 2.5608 - accuracy: 0.2216\n",
            "Epoch 1: val_loss improved from inf to 1.88213, saving model to model_ruen\n",
            "1900/1900 [==============================] - 773s 395ms/step - loss: 2.5608 - accuracy: 0.2216 - val_loss: 1.8821 - val_accuracy: 0.2855\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2ce3e8e170>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "model.fit((X_en_train, X_ru_dec_train), X_ru_out_train,\n",
        "             validation_data=((X_en_valid, X_ru_dec_valid), X_ru_out_valid),\n",
        "             batch_size=500,\n",
        "             epochs=1,\n",
        "             callbacks=[checkpoint]\n",
        "             )\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "Xa0l9pQItg8g"
      },
      "outputs": [],
      "source": [
        "def translate(text):\n",
        "    input_ids = encode(text.lower(), tokenizer_en)\n",
        "\n",
        "    input_ids = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "                                      [input_ids], maxlen=max_len_en, padding='post')\n",
        "\n",
        "\n",
        "\n",
        "    output_ids = [tokenizer_ru.token_to_id('[CLS]') ]\n",
        "\n",
        "    pred = model((input_ids, tf.cast([output_ids], tf.int32)), training=False)\n",
        "\n",
        "\n",
        "    while pred.numpy().argmax(2)[0][-1] not in [tokenizer_ru.token_to_id('[SEP]'),\n",
        "                                                            ]:\n",
        "        if len(output_ids) > max_len_ru:\n",
        "            break\n",
        "        output_ids.append(pred.numpy().argmax(2)[0][-1])\n",
        "        pred = model((input_ids, tf.cast([output_ids], tf.int32)), training=False)\n",
        "\n",
        "    return tokenizer_ru.decode(output_ids[1:])\n",
        "    # ' '.join([tokenizer_ru.id_to_token(i) for i in output_ids[1:]])"
      ],
      "id": "Xa0l9pQItg8g"
    },
    {
      "cell_type": "code",
      "source": [
        "def translate(texts):\n",
        "    input_ids = encode(texts.lower(), tokenizer_en)\n",
        "\n",
        "    input_ids = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "                                  input_ids, maxlen=max_len_en, padding='post')\n",
        "\n",
        "    output_ids = [[tokenizer_ru.token_to_id('[CLS]')] for i in range(len(texts))]\n",
        "\n",
        "    pred = model((input_ids, tf.cast(output_ids, tf.int32)), training=False)\n",
        "    end_tokens = [tokenizer_ru.token_to_id('[SEP]')] * len(texts)\n",
        "\n",
        "    while not all(token in end_tokens for token in pred.numpy().argmax(2)[:, -1]):\n",
        "        if len(output_ids[0]) > max_len_ru:\n",
        "            break\n",
        "        for i in range(len(texts)):\n",
        "            if end_tokens[i] not in pred.numpy().argmax(2)[i]:\n",
        "                output_ids[i].append(pred.numpy().argmax(2)[i][-1])\n",
        "\n",
        "        pred = model((input_ids, tf.cast(output_ids, tf.int32)), training=False)\n",
        "\n",
        "    outputs = [tokenizer_ru.decode(output_id[1:]) for output_id in output_ids]\n",
        "    return outputs\n"
      ],
      "metadata": {
        "id": "uCi9iPPgV9f7"
      },
      "id": "uCi9iPPgV9f7",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "7d0ee1b8",
      "metadata": {
        "id": "7d0ee1b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4af6e0b7-87e1-43e1-f2f8-32641a3db624"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'вы можете перевести эту рекомендацию >>?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "translate(\"can you translate this sentence?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "aa0b57d2",
      "metadata": {
        "id": "aa0b57d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "facd504d-a6ba-4bc9-9381-6de0c168bd72"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "translate(\"please translate this sentence into russian\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc8dbbbd",
      "metadata": {
        "id": "fc8dbbbd"
      },
      "outputs": [],
      "source": [
        "# translate(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5e2071b",
      "metadata": {
        "id": "a5e2071b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BLEU"
      ],
      "metadata": {
        "id": "-ZPgGsEl8Cul"
      },
      "id": "-ZPgGsEl8Cul"
    },
    {
      "cell_type": "code",
      "source": [
        "en_sents_test = open('opus.en-ru-test.en').read().lower().splitlines()\n",
        "ru_sents_test = open('opus.en-ru-test.ru').read().lower().splitlines()"
      ],
      "metadata": {
        "id": "TbLvCxxlFCn6"
      },
      "id": "TbLvCxxlFCn6",
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm_notebook"
      ],
      "metadata": {
        "id": "SO-I0KoRZWgo"
      },
      "id": "SO-I0KoRZWgo",
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import trange"
      ],
      "metadata": {
        "id": "gtyAWj_KVYf-"
      },
      "id": "gtyAWj_KVYf-",
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translations = []\n",
        "\n",
        "for i in range(len(ru_sents_test)):\n",
        "    translations.append(translate(ru_sents_test[i]))"
      ],
      "metadata": {
        "id": "Dy0cRSoLFC0k"
      },
      "id": "Dy0cRSoLFC0k",
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translations"
      ],
      "metadata": {
        "id": "Cuj_lcoUFg9W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7b57b88-8d4e-42f7-d71d-874f6fa17183"
      },
      "id": "Cuj_lcoUFg9W",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['текущее время hourly 1',\n",
              " 'в.',\n",
              " 'не знаю, что у нас.',\n",
              " 'что?',\n",
              " 'г.',\n",
              " 'это не так.',\n",
              " '- не волнуйся, тодди',\n",
              " 'posted : 22 dec 2007, 22 : 22',\n",
              " 'я подзила, что за счет.',\n",
              " '«: июль 2011, 17 : 15 : 34 »',\n",
              " 'ну, в разделен.',\n",
              " 'в.',\n",
              " 'малага и ситероидов',\n",
              " 'текущее время',\n",
              " '',\n",
              " 'в конце концов, это в конце концов, в конце концов,',\n",
              " '',\n",
              " 'не в отличие от бишкеки, но не так ли?',\n",
              " 'это самое, что - то есть, к тому, что это имеет значение.',\n",
              " 'http :// www. culture. ru / f / viewtopic. php? m2',\n",
              " 'трики, что...',\n",
              " 'и я не могу.',\n",
              " 'выучиле.',\n",
              " 'в.',\n",
              " \"senten ' renten ' t could to go to go\",\n",
              " 'устойчивое рекомендация >> бюджетные материалы',\n",
              " '- он из - за матки.',\n",
              " 'un ( 19 )',\n",
              " 'как можно мгновенно получить?',\n",
              " '2. 6.',\n",
              " 'и я буду, что не за это.',\n",
              " 'в.',\n",
              " 'в.',\n",
              " '8.',\n",
              " 'начало',\n",
              " 'не очень хорошо.',\n",
              " 'в.',\n",
              " 'из серии \"#',\n",
              " '',\n",
              " '- в одном из них.',\n",
              " 'будущая на вкусе, что не из них.',\n",
              " 'в д.',\n",
              " 'и да, учитывая, что это было, и да.',\n",
              " '- это - ка.',\n",
              " '- крот, и все время.',\n",
              " 'не волнуйся,',\n",
              " 'да, на микровицеи.',\n",
              " 'теперь, если вы детишки, знаете, что...',\n",
              " 'и - каш - 117 42 42 420',\n",
              " 'начало лечения',\n",
              " 'я водиля любовь, гриффини,',\n",
              " 'а также в работе с точки зрения антивизических характеристик.',\n",
              " 'не волнуйся, что зашли.',\n",
              " 'и сжимания, головной боли, холод и коротко.',\n",
              " 'не могу быть эмоционально, чтобы понять, я знаю.',\n",
              " 'д. 5 out of 5 based on 1479 ratings.',\n",
              " 'это ваша честь.',\n",
              " 'хорошо, хорошо.',\n",
              " 'но если бы сжимать все, он все еще.',\n",
              " 'он начинает',\n",
              " 'я предпочитаю представить себе, цветные украшения.',\n",
              " 'влажность',\n",
              " '',\n",
              " '- vol. 118, no. 8.',\n",
              " 'ну, ты не знаешь, что у тебя так же.',\n",
              " '',\n",
              " 'в 14 веке, и в провинциях.',\n",
              " 'длина связи',\n",
              " 'в.',\n",
              " 'да, но он не для просмотра.',\n",
              " '\" и пред.',\n",
              " '- нет, не волнуйся.',\n",
              " 'это не так.',\n",
              " '- это не было.',\n",
              " 'и в целом.',\n",
              " 'за счет загрузки рубля руб.',\n",
              " 'не прикровности.',\n",
              " 'длина',\n",
              " 'файлы : copu',\n",
              " '- да.',\n",
              " '\" в вьетнаме \" валерие, что мы делаем в вьетнаме.',\n",
              " 'в вашей корзине.',\n",
              " 'в.',\n",
              " 'и в 2004 году.',\n",
              " 'posted : 22 jul 2010, 22 : 43',\n",
              " '- как?',\n",
              " 'как поживает, как пожить?',\n",
              " 'и к.',\n",
              " 'не из - зази и не было.',\n",
              " 'не волнуйся, что у нас.',\n",
              " 'возможно, мы все были все, что были все в этом.',\n",
              " 'и в.',\n",
              " 'с точки зрения использования.',\n",
              " 'не в стиле \" дневник \" в \" сетке \".',\n",
              " 'не волнуйся,',\n",
              " '',\n",
              " '- это захари.',\n",
              " 'рекомендация ( рекомендация 2180',\n",
              " 'три износки',\n",
              " 'регистрация за счет внебюджетных ресурсов',\n",
              " 'но на время... не трати.',\n",
              " 'регистрация : 02 - 11, 15 : 14',\n",
              " 'на складе',\n",
              " 'длина 1 11 2 3 4 6 7 8 9 10 11 >+++++',\n",
              " 'в.',\n",
              " '2. 3. 2. 3. 3. 3. 5. 5',\n",
              " '( опсклония ) 4968 **** телефон',\n",
              " 'и, перехватить, септизи.',\n",
              " '[ 03 : 53 ] /-++++++++++++',\n",
              " 'да.',\n",
              " '- каштвое представление материалов?',\n",
              " 'он проверяет телефонные',\n",
              " 'не могу говорить о том, что это значит.',\n",
              " '# 7 horridon 25hc ( 00 : 10 : 23 )',\n",
              " '- что - то я не из фруктовых материалов.',\n",
              " '- то есть, не сбалансированный?',\n",
              " 'производительность, эластическая',\n",
              " '',\n",
              " '- да, бандит, он начинает критику.',\n",
              " 'понятия',\n",
              " '',\n",
              " 'это знает, что он делает?',\n",
              " '- да.',\n",
              " '- в.',\n",
              " '-',\n",
              " '',\n",
              " 'я могу получить файлы, чтобы',\n",
              " 'а также не распознавания.',\n",
              " '- анархия',\n",
              " 'поощрение и защита коренных народов и окружающей среды, являются нерегулярными людьми,',\n",
              " 'it and gets of love <#++++++++++',\n",
              " '',\n",
              " 'что мне надо быть хорошим, чтобы быть в восторге.',\n",
              " '',\n",
              " 'у нас есть детишки, и лодыжка.',\n",
              " 'в.',\n",
              " 'и что и что, если бы не было с лифтом?',\n",
              " 'а также, хижины, хижины.',\n",
              " 'с помощью лечения',\n",
              " 'не совсем один из них составляли 5 out of 5 based on 33233 ratings.',\n",
              " 'в.',\n",
              " 'в.',\n",
              " '- длина',\n",
              " 'размер',\n",
              " 'как в качестве оптостей?',\n",
              " '- да, но, но у вас есть?',\n",
              " 'малая, тема безжалостная.',\n",
              " 'и в.',\n",
              " '',\n",
              " 'условия работы от унижений для просмотра для просмотра на родных.',\n",
              " 'в.',\n",
              " '',\n",
              " 'вы, вы любители, что из них будут делать.',\n",
              " 'vip ( ром ) - sjos ( brim )',\n",
              " 'это это - это из - за тугого.',\n",
              " 'я не могу.',\n",
              " 'три обои (*)',\n",
              " '3 : 2, 12, 12, 19, 26, 41, 41',\n",
              " 'в.',\n",
              " '- септические',\n",
              " 'все хорошо, что не из - за варварки.',\n",
              " 'а.',\n",
              " 'длина# 1600',\n",
              " 'и в.',\n",
              " '- давно телефонные',\n",
              " '- оп - спектра - спектра - металлических изделий.',\n",
              " 'это в прошлом.',\n",
              " 'в 2007 году',\n",
              " 'не волнуйся.',\n",
              " 'я не знаю, мы не можем быть.',\n",
              " 'материалы,',\n",
              " 'предгори мне, что за то, что зашли.',\n",
              " '- в общем,',\n",
              " 'верно, не надо, но не прикровности.',\n",
              " 'в.',\n",
              " 'название :',\n",
              " '« reply # 1 on : june 22, 2007, 05 : 22 : 22 pm »',\n",
              " 'что за ним, возможно, в порядке.',\n",
              " 'начало :',\n",
              " 'из - за всех стран, все прошло?',\n",
              " '34 05 / 02 / 2009 monday 3',\n",
              " 'да, что в этом нет никакого значения.',\n",
              " '- да.',\n",
              " 'в.',\n",
              " '',\n",
              " 'я в пространстве.',\n",
              " 'цель оценки, размер',\n",
              " '- в общем, все в порядке.',\n",
              " 'это подло, что у меня есть, что у меня есть сердце.',\n",
              " 'не эмоционально, ночные',\n",
              " 'и в стилести.',\n",
              " 'trans / wp. 5 / 2000 / 4 / add. 1 / rev. 1.',\n",
              " 'с 11 до 14, 1 до 14, 3.',\n",
              " '- я знаю,',\n",
              " 'производительность за счет.',\n",
              " 'в.',\n",
              " 'и 17, в этом разделенный показатель.',\n",
              " 'в версии.',\n",
              " '- текущее время телефонные материалы',\n",
              " 'если бы не было.',\n",
              " 'это - ти - э - э.',\n",
              " 'и все, что это было.',\n",
              " 'в.',\n",
              " 'поиск, спасибо.',\n",
              " 'it...',\n",
              " 'активные игры, com, +++++++++++++',\n",
              " 'это не из - за него.',\n",
              " 'в.',\n",
              " '2 % 73 12 / 10 / 2014 monday 1',\n",
              " 'не, мы не можем говорить о том, что в пекаре.',\n",
              " 'малая ;',\n",
              " 'ну, что мы не имеем дело.',\n",
              " '',\n",
              " 'в.',\n",
              " 'https :// www. форум - forums / forums / 31 /-',\n",
              " 'все их в порядке.',\n",
              " '- в.',\n",
              " '- анархические',\n",
              " 'не могу, но, в.',\n",
              " 'длина файлов 47. 28',\n",
              " 'не волнуйся, но.',\n",
              " '- это он. дозировками',\n",
              " 'ну, если бы не было.',\n",
              " 'на вкусе.',\n",
              " 'это правильный из - за этого права.',\n",
              " '\" в \" к 8 - х - х - х - х?',\n",
              " 'я буду признателен за 15 : 00, 16 : 00 и в 17 : 00.',\n",
              " '- в этом стиле, но?',\n",
              " 'но у вас есть, что не зашли.',\n",
              " 'я люблю, самые популярные',\n",
              " 'а также, что из них?',\n",
              " '6. 1.',\n",
              " '- да.',\n",
              " 'в.',\n",
              " 'вы, я сш, я дозиричу.',\n",
              " 'леп также могли бы пользоваться+++#+#+#++++',\n",
              " 'в.',\n",
              " 'что я закрыла анальные',\n",
              " 'для оплаты в зоне в зоне.',\n",
              " 'но если бы не было, то что за это, то что за их пределами.',\n",
              " 'на уровне ) и вдохновение духовного района в г.',\n",
              " 'соняя, на всю ночь.',\n",
              " '- да.',\n",
              " 'это',\n",
              " '- но - но - да.',\n",
              " 'и к тому же, как и к тому,',\n",
              " 'за счет принятия мерки...',\n",
              " '',\n",
              " 'спок, это будет для загрузки',\n",
              " '- и?',\n",
              " 'не дёрки, что я - казна.',\n",
              " '- в.',\n",
              " '- кетво.',\n",
              " 'в другом, но мне не надо.',\n",
              " 'с помощью опции.',\n",
              " 'и в этом направлении, и к этому.',\n",
              " '- и я хочу вернуть его.',\n",
              " 'отягация, возможно.',\n",
              " '( тел.',\n",
              " 'в условиях.',\n",
              " '-',\n",
              " 'в.',\n",
              " 'в.',\n",
              " '',\n",
              " 'я буду в этом роде, а я буду лигуть это.',\n",
              " 'в.',\n",
              " 'она писала в том, что касается стойких органических загрязнителей.',\n",
              " 'текущее время hourly 1',\n",
              " 'подицик из - за груди, джоун.',\n",
              " 'как он, как он - то, как он - то, так.',\n",
              " 'для вас в стилейке.',\n",
              " '',\n",
              " '29 / 04 / 2009, 22 : 22',\n",
              " 'не заездами, чтобы',\n",
              " 'из - за одного из двух.',\n",
              " '###*#+++++++++++++++',\n",
              " 'он в составлен в составе,',\n",
              " 'и в качественно - релиза.',\n",
              " 'environs of the lay - 100 - 200 - 200.',\n",
              " 'если бы не было, то что бы ни было.',\n",
              " 'it is currently sun may 22, 2016 3 : 22 am',\n",
              " 'а в ресторане это он на кухне и.',\n",
              " 'в.',\n",
              " '',\n",
              " 'я могу помочь им.',\n",
              " 'но, к.',\n",
              " 'у тебя есть ваша светлость...',\n",
              " 'в школе \" 240 \"',\n",
              " '- я не могу пить из - за хранения',\n",
              " '- да.',\n",
              " '',\n",
              " '\" с.',\n",
              " 'я бы не могла быть с тобой, как я?',\n",
              " 'a / c. 4 / 60 / 5 / add. 33 )',\n",
              " 'в.',\n",
              " 'назад... самые красивые города.',\n",
              " 'rentuttttttttttttt »',\n",
              " '- да.',\n",
              " 'в.',\n",
              " 'но... возможно, он просто разгролит?',\n",
              " 'длина элайди',\n",
              " '- матки, я',\n",
              " 'начало :',\n",
              " 'в.',\n",
              " 'я не знаю, что ты делаешь?',\n",
              " 'размер погоды ( мм ): 10',\n",
              " '60 % и возможности использования новых линий и использования новых приложений.',\n",
              " 'начало',\n",
              " 'телефонные',\n",
              " 'да, он не был.',\n",
              " '- текущее время',\n",
              " 'да, я и др.',\n",
              " 'соняяяя, но в одном месте был прав.',\n",
              " 'страница, 01 / 14 / 2010 - 01 : 29',\n",
              " 'это время и на пути к.',\n",
              " 'все эти деньги.',\n",
              " 'да, это не было, он не был в милях.',\n",
              " 'в.',\n",
              " '[ skipper ]',\n",
              " 'google visited last this page october 12, 2017, 05 : 45 : 10',\n",
              " '',\n",
              " 'и так же в разделении.',\n",
              " 'я, как разгролит, да, да.',\n",
              " 'я бы предпочла, чтобы быть из них.',\n",
              " 'тема : -',\n",
              " '( за счет ) из унижений.',\n",
              " 'это очень дорогое значение для отца.',\n",
              " 'я в одном время, как я начинаю изучать всюду!',\n",
              " 'и конечно, и и точные.',\n",
              " 'я люблю много времени',\n",
              " 'в.',\n",
              " 'не перелом, и ни в коем случае не переезжать.',\n",
              " 'не помешало.',\n",
              " 'в отличие от груди.',\n",
              " '- да.',\n",
              " 'это захари и на это время.',\n",
              " '1838 года и его в целом.',\n",
              " 'и мы с нами будем делать.',\n",
              " 'что захари.',\n",
              " 'в одном из них.',\n",
              " 'я был в составлен страницы :',\n",
              " '- да.',\n",
              " 'это за пределами.',\n",
              " 'location',\n",
              " 'северный область + 21 ° c',\n",
              " 'не волнуйся, не волнуйся.',\n",
              " '- да.',\n",
              " 'не надо.',\n",
              " '- это был ингалоя.',\n",
              " '23 май 2006',\n",
              " '[ наблю ]',\n",
              " 'и не могли бы понять.',\n",
              " '- да.',\n",
              " '- да.',\n",
              " 'это и это - у тебя... часть.',\n",
              " 'и все равно.',\n",
              " '- как разгролита?',\n",
              " 'мы все вместе с ним.',\n",
              " 'по вопросам старения',\n",
              " 'он был представлен в кафе, 840',\n",
              " 'в.',\n",
              " 'на сцене.',\n",
              " 'он по телефону, чтобы',\n",
              " 'да, но и не будем ссориться, как и не закрывает.',\n",
              " '- каш ( ф.: 519 ) 769 **** телефон',\n",
              " '- да.',\n",
              " 'регистрация сообщений',\n",
              " '- в.',\n",
              " 'длина ( 1 )',\n",
              " '- это было, так, как',\n",
              " '',\n",
              " 'я люблю, что это с тобой.',\n",
              " 'рекомендация джима, прямые рейсы до аэропорта',\n",
              " 'это не так.',\n",
              " 'a / 60 / 115, a / 60 / 261 и a / 60 / 158 )',\n",
              " 'что, рестораны, рестораны,?',\n",
              " '07. 12. 2017 6 : 41',\n",
              " 'в.',\n",
              " '',\n",
              " '# 20 цзи - кунь 10, 25 : 11 )',\n",
              " '',\n",
              " 'al - naz. com. com',\n",
              " 'в.',\n",
              " 'в.',\n",
              " 'как обои ( пенсильвания )',\n",
              " 'начало продукции и использование данных о возмещении им :',\n",
              " 'в прошлом году не на самом деле.',\n",
              " 'тризи, что из чего из родителей?',\n",
              " 'длина ( 12 +)',\n",
              " '- а также для определения',\n",
              " 'он знает, что он может быть',\n",
              " '- это не значит.',\n",
              " 'а.',\n",
              " 'размеры',\n",
              " 'и все уладить.',\n",
              " 'и так и не было.',\n",
              " 'длина#++++++++++++++++',\n",
              " '- ну, давай...',\n",
              " 'версия',\n",
              " '',\n",
              " 'начинаются с vnzania',\n",
              " 'это не может быть, это не может быть, и это не так.',\n",
              " 'http :// wordpress. lv',\n",
              " '',\n",
              " 'рекомендация000000',\n",
              " '- это не имеет значения.',\n",
              " 'и не волнуйся.',\n",
              " '- да.',\n",
              " '24. август 2011',\n",
              " '- да.',\n",
              " 'как и в.',\n",
              " 'и не было.',\n",
              " 'фиц, и вкладка.',\n",
              " 'в.',\n",
              " '- привет, 1986 год.',\n",
              " '15 : 00 – на обед и паб ( 16 +)',\n",
              " 'размеры',\n",
              " 'три и я просто пытаюсь',\n",
              " 'соняя, а потом, на самом деле...',\n",
              " 'в.',\n",
              " 'все объявления о стойких органических загрязнителейх.',\n",
              " '-',\n",
              " 'в украине и',\n",
              " 'северный телефон + 27 ° c',\n",
              " 'кет, арии, дрейна!',\n",
              " '',\n",
              " 'найти такие ii. на примере, так в том числе',\n",
              " 'как напечататьны?',\n",
              " 'в качестве основы для себя,',\n",
              " '',\n",
              " 'it, danture go!!!##++++++++',\n",
              " 'в.',\n",
              " 'трии, это за представление материалов.',\n",
              " 'время постоянного с',\n",
              " 'начало :',\n",
              " 'эластичные материалы, касающиеся использования.',\n",
              " 'это начало.',\n",
              " 'и в.',\n",
              " 'в.',\n",
              " 'я не могу быть в восторге!',\n",
              " '- да.',\n",
              " '- да.',\n",
              " 'в.',\n",
              " 'posted : 22 mar 2007, 22 : 22',\n",
              " 'от :, под описание : 2007 - 11 : 12 : 12',\n",
              " 'http :// www. un. org / docs / r - rss. pdf )',\n",
              " 're : 1. 3. 3. 1. 3',\n",
              " \"javascriptia, it ' s non\",\n",
              " 'не так ли на карте, детка, дачи, да?',\n",
              " 'он прав, верно, это набле?',\n",
              " 'длина#',\n",
              " 'пек, дико - сан - ку - куа,',\n",
              " 'я люблю орху в \" нун, я вернулся в окно.',\n",
              " 'соня, не так ли в этом зале.',\n",
              " 'в.',\n",
              " 'не знаю, возможно, это не так, как и.',\n",
              " '5 % от 18 лет.',\n",
              " 'все все еще не могли бы принять все меры.',\n",
              " 'в.',\n",
              " 'на основе.',\n",
              " 'münn, kjuj, kaska,',\n",
              " 'в.',\n",
              " 'влажность',\n",
              " 'эти деньги :',\n",
              " 'из них были бы на дёрке.',\n",
              " '2003 года на и к.',\n",
              " 'в.',\n",
              " 'в.',\n",
              " 'в.',\n",
              " 'http :// www. voltaire. org / article18. html',\n",
              " '',\n",
              " 'в.',\n",
              " 'длина ( 1 )',\n",
              " '- да.',\n",
              " 'и в.',\n",
              " 'в.',\n",
              " 'я - это не могу.',\n",
              " 'из - за части и унижений.',\n",
              " 'в меню в каталоге.',\n",
              " 'iv ) размеры материалы',\n",
              " 'длина#',\n",
              " 'что такое в провинцияхх?',\n",
              " 'таблица - 16 января 2010 »',\n",
              " '- мы хотим получить в ресторане...',\n",
              " '- это за 80 000 до.',\n",
              " 'я был вломке.',\n",
              " '- да.',\n",
              " 'в.',\n",
              " 'а также не на одной части.',\n",
              " 'я на задаю многого времени',\n",
              " '- ответные сведения о работе',\n",
              " 'и я люблю.',\n",
              " 'мы знаем, что он за счет внебюджетных ресурсов.',\n",
              " 'так, мерка не связанных с',\n",
              " '- как двестические',\n",
              " 'телефонные',\n",
              " '- да.',\n",
              " 'сайт :',\n",
              " 'и с.',\n",
              " 'а также на основе сотрудничества и перспективы использования.',\n",
              " 'на уровне.',\n",
              " 'это возможно, но...',\n",
              " 'что он очень мило и лакон.',\n",
              " '- это - ферма - это не важно.',\n",
              " 'в.',\n",
              " 'в стилех и в рози.',\n",
              " 'http :// www. ru / fkam / cd / cd / usb / usb /',\n",
              " 'в.',\n",
              " '4. 2 из них должны принять соответствующие меры :',\n",
              " 'все все это, кет, кекс.',\n",
              " '- я буду признателен за',\n",
              " '24 - 12 - 2008, 1 : 18 pm',\n",
              " 'и не могу быть прав человека, а также в порядке.',\n",
              " 'что, что он делает, не волнуйся.',\n",
              " '- да.',\n",
              " 'а.',\n",
              " 'в.',\n",
              " '36 06 / 04 / 2013 monday 1',\n",
              " '',\n",
              " '- я просто славный соняяяя',\n",
              " 'текущее время hourly 1',\n",
              " 'all times are gmt + 5. the time now is 05 : 22 pm.',\n",
              " 'время восходаяция',\n",
              " 'что ж, он делает, что - то, что это - то - то.',\n",
              " 'мы вместе с ними были, что он на тонкие.',\n",
              " '2. 2. 2.',\n",
              " 'текущее время лечения',\n",
              " '\" септики \"',\n",
              " 'в.',\n",
              " 'в.',\n",
              " 'как разгрораживание?',\n",
              " 'если бы не был, то не было, он был бы прав.',\n",
              " 'сша.',\n",
              " '- да, что за рулем.',\n",
              " 'на региональном уровне, видео -',\n",
              " 'начинаются с. 8 – 12.',\n",
              " '- если на телепорте не совпадают...',\n",
              " 'и я не могу быть, чтобы избавиться от.',\n",
              " 'в.',\n",
              " 'и не захари.',\n",
              " 'в.',\n",
              " 'я могу быть в стиле.',\n",
              " 'начало в.',\n",
              " 'в.',\n",
              " '- да.',\n",
              " 'в сердце.',\n",
              " 'он не дози, как и я понимаю, так и не было.',\n",
              " 'это не из - за',\n",
              " 'я будущий вклад в меня в сердце.',\n",
              " 'он и с поверхности',\n",
              " 'это не из - за кроликов, не из - за одного из них.',\n",
              " '- все апартаменты',\n",
              " '- с - куа - джоун ) 201604 **** телефон',\n",
              " '- заж, лепузизи',\n",
              " 'соняяя, д. и от 06 / 06 / 06 / 13 / 13',\n",
              " '2. 1. 2. 1. 2. 1.',\n",
              " 'от времени, но и не надо.',\n",
              " 'iccd : + 39. 0431. 203671',\n",
              " 'у вас есть из - за кроликов, а не так.',\n",
              " 'так я накровность всех.',\n",
              " 'в.',\n",
              " '2. 2. 1. 2. 1. 1.',\n",
              " 'и в.',\n",
              " '- ic - vi. netherneto de lan - az - бельгия \".',\n",
              " 'moon, а также для лечения',\n",
              " 'ноябрь 2009 года петрозаводская область в бишкеке.',\n",
              " 'в апреле 1976 года.',\n",
              " 'длина :',\n",
              " '- да.',\n",
              " 'в.',\n",
              " 'я могу убить их от любви?',\n",
              " 'что за счет.',\n",
              " 'в.',\n",
              " '30 ноябрь 2017, 18 : 30 : 21',\n",
              " '« on : october 12, 2010, 12 : 22 : 22 pm »',\n",
              " 'и в.',\n",
              " '- да, кет - набльке?',\n",
              " 'и лечение >>',\n",
              " 'часть 200',\n",
              " 'прочие материалы, 7 - июнь, сентябрь 2005 года',\n",
              " 'в.',\n",
              " 'малага, три из каких?',\n",
              " 'но не только для определения',\n",
              " 'регистрация 6',\n",
              " '2 12 / 01 / 2014 monday 1',\n",
              " '- это - соединение.',\n",
              " '1234040 **** телефон',\n",
              " 'в.',\n",
              " 'за счет использования в отношении унижений.',\n",
              " 'это не так.',\n",
              " 'мио, я наполнен тоддом очень впечатляет.',\n",
              " 'не могу использовать меня, как и я могу.',\n",
              " 'не за счет решения безжалостная.',\n",
              " 'и я думаю, что это будет в безжалостная структурах.',\n",
              " 'я ищу летнее время hourly 1',\n",
              " '20. 155. 146. 218',\n",
              " 'и влажность, спасибо за счет лечения.',\n",
              " 'дата публикации : 16 октября 2014 г.',\n",
              " '- да.',\n",
              " \"moon, i ' ll ' ll\",\n",
              " 'я буду признателен за выполнением.',\n",
              " 'размеры ( м ): 2. 3',\n",
              " 'введение',\n",
              " 'на колени.',\n",
              " 'привет, кая.',\n",
              " '',\n",
              " 'и за счетить мечту.',\n",
              " 'в.',\n",
              " 'диаграмма 3',\n",
              " '3 часа, 60 x 1800 ( 3 часа 60 x 60 x 54 см )',\n",
              " '2. 1. 2. 1. 2. 1. 1.',\n",
              " 'сша ), 1.',\n",
              " 'и к.',\n",
              " '',\n",
              " '- привет, все, очень мило.',\n",
              " '0. 02380 ***',\n",
              " 'цена на час : 150 eur',\n",
              " '- да.',\n",
              " 'начало обновления',\n",
              " 'программа обучения в области борьбы с ними.',\n",
              " '- да.',\n",
              " '# 3 javascript 25 ( 00 : 08 : 20 )',\n",
              " 'погода,# 1600',\n",
              " 'это время для проведения.',\n",
              " 'не без разрешения, как вы это таке?',\n",
              " 'начинаются с 26 августа',\n",
              " 'в отношении размерах не будет.',\n",
              " 'мы могли бы использовать и в ресторане',\n",
              " '15 01 / 07 / 2016 monday 1',\n",
              " '22. 06. 2016, 11 : 56 # 64',\n",
              " 'на уровне стран - 2003 годов.',\n",
              " 'в.',\n",
              " '12 шат ( 00 : 03 : 46 )',\n",
              " 'начало ( хооептических обзоров );',\n",
              " 'moon / € € 35, 00 для тиража ( от 4 до 12 лет ).',\n",
              " '# 11 изначалий 10 ( 00 : 06 : 17 )',\n",
              " 'не совсем.',\n",
              " 'что за такое, что из - за толстовки.',\n",
              " '« родриго » и ценах и ценах.',\n",
              " 'posted : 22 sep 2010, 22 : 31',\n",
              " 'в.',\n",
              " 'а как же материалы?',\n",
              " 'бави, септика, но и я понимаю.',\n",
              " 'и он - это не может быть в состоянии пользоваться вашим правом.',\n",
              " '# 9 immerseus 25hc, fallimento ( 00 : 07 : 26 )',\n",
              " 'не надо, как разгровы.',\n",
              " '- это было бы.',\n",
              " '2.',\n",
              " 'в.',\n",
              " 'а потом, чтобы помочь им, чтобы быть в этом доме?',\n",
              " 'длина 52400nkannntiantiania. lv',\n",
              " '- и свечи.',\n",
              " 'в бугеке?',\n",
              " '',\n",
              " 'я не могу быть не в стилей низкой цене, что, что, что,',\n",
              " 'в ценах в ценах.',\n",
              " 'не в.',\n",
              " '',\n",
              " 'трио ( трика )',\n",
              " '\" выучиля \"',\n",
              " 'кетфильки',\n",
              " '',\n",
              " 'не совсем ценностям.',\n",
              " 'джу, и не знаю об этом.',\n",
              " 'и к.',\n",
              " 'message toncencencen',\n",
              " 'я.',\n",
              " '( видео ) 7678 **** телефон',\n",
              " 'на глазах.',\n",
              " 'это время для получения.',\n",
              " 'если бы не хотелось, что - то есть.',\n",
              " '?',\n",
              " 'sentzenttt - 31 августа 2001 года.',\n",
              " '- мы сжимаем?',\n",
              " '- спасибо.',\n",
              " 'как я понимаю,',\n",
              " 'бо, ана, ана, не смотри.',\n",
              " 'в размер 4 - м.',\n",
              " 'i в 702 - м.',\n",
              " 'но мы будем с ними, как - нибудь',\n",
              " '— страница из',\n",
              " '12. 08. 2012, 19 : 26',\n",
              " '\" - на 4 - ти - е.',\n",
              " 'в.',\n",
              " 'это из - за какого рода - то тонкие аспекты.',\n",
              " '( 00 : 09 )',\n",
              " 'огниги, лечу,',\n",
              " 'г.',\n",
              " '- длина#*#*#*#*#*#*#*#',\n",
              " 'и в этом.',\n",
              " 'я так и лечу.',\n",
              " '« on : september 04, 2007, 05 : 22 : 26 pm »',\n",
              " 'для загрузки',\n",
              " 'и что, что мы должны быть, что мы должны быть в стиле.',\n",
              " '- хат - ха - ха - ха - ха - ха - ха -',\n",
              " 'я люблю тебя, чтобы свести к сердцу.',\n",
              " 'в этом году он смотрит на микро - мицкари.',\n",
              " 'длина#',\n",
              " '# 1 immerseusus ( 00 : 02 : 26 )',\n",
              " 'в.',\n",
              " 'лапухать, да.',\n",
              " 'что я могу жить с ними?',\n",
              " '10529',\n",
              " '-',\n",
              " 'это не начало',\n",
              " 'в.',\n",
              " '- так и страница',\n",
              " 'ну, конечно, это не в.',\n",
              " 'в.',\n",
              " 'сайт компании « rent »',\n",
              " 'добавлено : 12 : 28 : 59 /- 22',\n",
              " 'в.',\n",
              " 'опубликовано',\n",
              " 'я не могу, лабиринт.',\n",
              " '- да.',\n",
              " 'длина 840 ***',\n",
              " 'posted : 27 apr 2007, 22 : 22',\n",
              " 'в.',\n",
              " 'он - каш и может быть.',\n",
              " 'i )]#++++++#++++++++',\n",
              " 'http :// www. un. org /',\n",
              " 'в 3 и летнего лет.',\n",
              " '[ джиллы ] [...]#',\n",
              " 'матильоньего?',\n",
              " '- матки, длина',\n",
              " '8 см. например, « мы купим », под давлением, 2000.',\n",
              " '- в.',\n",
              " 'да, лабка, соняяяяя твоя...',\n",
              " 'просто в конце концов, не так ли.',\n",
              " 'объем минералов в fruits, vegetables, fats, cereals, spices and nuts rich in ken',\n",
              " '2014 г. он - это оплодоз.',\n",
              " '- не могу?',\n",
              " '- да, на самом деле?',\n",
              " 'вымыли - фиктивный бакое?',\n",
              " 'я гриффин не за счет.',\n",
              " '- да.',\n",
              " 'не так и не очень хорошо в стилейке.',\n",
              " 'это не эмоционально',\n",
              " '- каш - ка.',\n",
              " 'и в целом, это непростительно.',\n",
              " 'это за чушь.',\n",
              " 'это - за лекарство.',\n",
              " 'в комое.',\n",
              " 'на берегу.',\n",
              " 'joined : 24 /- 1 /- 1',\n",
              " 'я не могу читать музыку, не могу.',\n",
              " 'как и к нему, как вы, как только вы некурили.',\n",
              " 'мы братьями были связаны с другом',\n",
              " 'что захари не помешала.',\n",
              " 'и в.',\n",
              " 'и больше не будет.',\n",
              " 'в.',\n",
              " '5. 10. mell - 5, россия – 2, zh - zm',\n",
              " '- хорошо.',\n",
              " 'размеры :',\n",
              " '- да.',\n",
              " 'и в.',\n",
              " 'работами и на тоне.',\n",
              " 'текущее время :',\n",
              " '10 октября 2011 ( 484. 6 k3 )',\n",
              " '03. 03. 2010 18 : 44',\n",
              " 'и в.',\n",
              " '',\n",
              " '- я хочу снять с ними.',\n",
              " '# 9 immerseusion ( 00 : 03 : 30 )',\n",
              " 'в.',\n",
              " 'кьюи... он в больнице.',\n",
              " 'но не так, как и другие',\n",
              " 'но он на мапуке в маске.',\n",
              " 'как я раскрою, как я раскрою?',\n",
              " 'что захари что - нибудь в мире.',\n",
              " 'начало',\n",
              " 'хорошо, на все время.',\n",
              " 'в отношении унижений ;',\n",
              " 'в.',\n",
              " '- да.',\n",
              " 'в.',\n",
              " '- да.',\n",
              " 'обоснование и права на получение баланса.',\n",
              " '- выучия обои?',\n",
              " 'в общем, в душевности, в цвете.',\n",
              " '29 - 633 - 67 - 56 + 375 - 29 - 75 - 33 - 33',\n",
              " 'и и он наберех.',\n",
              " '- к тому, что в доме?',\n",
              " 'и в соответствии с ними',\n",
              " 'в д.',\n",
              " '# 23 малкорок 10 ( 00 : 03 : 21 )',\n",
              " 'адрес : контактная связь @ ариизиирование',\n",
              " 'сайт php так же',\n",
              " 'javasc, j. ( 1897 ).',\n",
              " 'начало :',\n",
              " '24. 02. 2014 20 : 51',\n",
              " 'это не джеки, джеки, джеки',\n",
              " 'производительность в 4 %.',\n",
              " 'в.',\n",
              " 'it was crawled by',\n",
              " 'как и с тобой.',\n",
              " 'не волнуйся.',\n",
              " '- да.',\n",
              " '( s )',\n",
              " '- да.',\n",
              " 'на полях - чихаустройке.',\n",
              " 'ну, что зашли.',\n",
              " 'регистрация ( 2000 )',\n",
              " 'в мире.',\n",
              " 'в.',\n",
              " '- ка, сеуля в шатте, дровие.',\n",
              " '\" малая \"',\n",
              " 'цена.',\n",
              " 'если бы не было, то что в прошлом час.',\n",
              " 'может быть, мы с ними все время взлетят в прошлом?',\n",
              " 'возможно, не очень милой и не имеет значения для стран.',\n",
              " 'д.',\n",
              " '4 - 4 - 4 - 4',\n",
              " 'на самом деле, и с кусачи.',\n",
              " 'и набережении, не слишком много.',\n",
              " '- хорошо, чтобы помочь им в цирках?',\n",
              " 'на основе работы в области борьбы с антивицеотической.',\n",
              " 'и набережная.',\n",
              " 'в.',\n",
              " '- это',\n",
              " 'и он - это не имеет значения.',\n",
              " 'производительность и не было бы расти.',\n",
              " 'и и в.',\n",
              " '5 ) альтернативные',\n",
              " 'да, не знаю.',\n",
              " 'я - каш.',\n",
              " 'хал ( овея ) 5157 **** телефон',\n",
              " 'не так уж и не было.',\n",
              " 'от 13 августа 2004 года на и к.',\n",
              " 'и больше не будет, что у вас есть.',\n",
              " 'я знаю, что не могу получить для этого',\n",
              " 'в рамках инициативы « ате » в колледжей и технологий пуэрто - рико.',\n",
              " 'возможно, выучили?',\n",
              " '11. 03. 2013, 17 : 52',\n",
              " 'а.',\n",
              " 'это не то, что зашли.',\n",
              " 'д.',\n",
              " 'это просто соняя.',\n",
              " '- и твой партнер - каш - каш - каш.',\n",
              " '5 / add. 2.',\n",
              " '- телефонные материалы не содержат',\n",
              " '- мама джонса',\n",
              " 'не могу быть причиной.',\n",
              " 'на кухне',\n",
              " 'я зашла к сердцу, что я был в восторге.',\n",
              " 'фрр.) на хранение.',\n",
              " '\" пекинский транспорт',\n",
              " '- да, родная - качияя,',\n",
              " 'друг, что не будем',\n",
              " 'трики, как многообразие в микроволнован.',\n",
              " 'в.',\n",
              " '- соня, соня на 12 - ти.',\n",
              " 'это не может быть, чтобы быть в восторге от толстыми.',\n",
              " '- кет - кет?',\n",
              " 'и др.',\n",
              " 'и сжимается, что так и не бывает.',\n",
              " 'в одном, что за счетить.',\n",
              " '',\n",
              " '« reply # 6 on : june 04, 2011, 03 : 01 : 01 pm »',\n",
              " 'начало :',\n",
              " 'погода, эластическая',\n",
              " 'я могу изменить с этим',\n",
              " '- прочие материалы, не спрашивая',\n",
              " 'в.',\n",
              " '- да.',\n",
              " 'что он в провинциях матрасовые?',\n",
              " 'диаграмма 1',\n",
              " 'http :// www. newadd. org / republic / 0969. htm )',\n",
              " '2. 1. 3',\n",
              " 'so a / 58 / 364, тел.',\n",
              " '( греция )',\n",
              " 'все еще одно из - за толстокого района?',\n",
              " 'в.',\n",
              " '',\n",
              " 'не буду изучать условия для оценки использования в области использования в условиях.',\n",
              " '( 1967 ) от 22 ноября 1967 года и 338 ( 1973 ) от 22 октября,',\n",
              " '[+++++++++++++++++',\n",
              " 'и с помощью загрузки в упаковке, как и это оборудование.',\n",
              " 'и все же, как и, так и есть.',\n",
              " '- привет.',\n",
              " 'а также в дигетти.',\n",
              " 'и эрека - аналитого - каяка.',\n",
              " 'а что за что он подтверждает в в?',\n",
              " '',\n",
              " '- я с умаю?',\n",
              " 'в.',\n",
              " 'площадь участка >>',\n",
              " 'начало, макоус, пеггинский',\n",
              " 'за твое удовольствие.',\n",
              " 'диаграмма 1',\n",
              " 'и не волнуйся.',\n",
              " '- да.',\n",
              " '- да.',\n",
              " '',\n",
              " 'если бы не было, то что касается любви любви любви.',\n",
              " 'время для отдыха.',\n",
              " 'что обои координации устойчивого?',\n",
              " 'малага',\n",
              " 'лепур на телефонной части.',\n",
              " '\" кролики \" и \" кролики \".',\n",
              " 'и не обижайся.',\n",
              " 'в пердеке.',\n",
              " '[ [ и от д. http :// www. com /',\n",
              " 'и цветные.',\n",
              " 'в. институт по поддержанию мира 1969 года, 1978 и 1986 год.',\n",
              " 'в.',\n",
              " 'не волнуйся,',\n",
              " 'и я понимаю, что все могут быть',\n",
              " '# 13 consorteumns ( 00 : 02 : 58 )',\n",
              " 'у вас есть рецепты с сарой.',\n",
              " '- да.',\n",
              " 'все, что зашли.',\n",
              " 'я просто не могу оценить,',\n",
              " 'и в.',\n",
              " 'он плюральные с помощью в кухне!',\n",
              " 'в.',\n",
              " '- хорошо.',\n",
              " 'в общем, в общем, в стиле, толстокое в.',\n",
              " 'г. е.',\n",
              " 'в. лаб, лапухази, мне пора.',\n",
              " 'ну, что за счет.',\n",
              " 'http :// www. rkaka. html was not found on this server.',\n",
              " '- это \" все \" все захари \".',\n",
              " 'но, все в порядке.',\n",
              " 'начало 2015 года',\n",
              " 'да, что...',\n",
              " 'я хочу вернуть помощь в больнице, в любви.',\n",
              " 'это за счет использования.',\n",
              " 'не волнуйся, что не будем ссориться?',\n",
              " '',\n",
              " 'я не могу быть безжалостная оценка.',\n",
              " '- да, тао, тао - е и в.',\n",
              " 'я не могу принять участие в программе.',\n",
              " 'из - за - за - за - за лечения',\n",
              " '20. 12. 2008, 12 : 22',\n",
              " 'я понимаю, что',\n",
              " 'в.',\n",
              " 'трина',\n",
              " 'все и все, что у нас есть все, что у нас есть.',\n",
              " 'не волнуйся.',\n",
              " 'не могу говорить о том, что это поможет?',\n",
              " \"начало обновления it ' s\",\n",
              " '2. 1. 2. 1. 2. 1. 11 : 49 )',\n",
              " 'в достижении унижений.',\n",
              " 'длина# 1600',\n",
              " 'это название.',\n",
              " 'что, чтобы помочь им, как разгролиты.',\n",
              " 'текущее время, в частности, связанные с',\n",
              " 'товары >>',\n",
              " 'я не буду крутиться, но не так ли.',\n",
              " 'анаст ( ви - 2636 **** телефон',\n",
              " '',\n",
              " 'и ещё не было.',\n",
              " 'send private message to go down',\n",
              " '( таблица 30.',\n",
              " 'в отличие от друга.',\n",
              " 'размеры ( версия 3 декабря 2005 года',\n",
              " 'не менее 5 % по использованию использования в игре на трассель.',\n",
              " 'я за счет телефона, чтобы с использованием данных',\n",
              " 'в.',\n",
              " 'длина# 1600',\n",
              " 'что, что я люблю мечту, что у тебя есть своя.',\n",
              " 'it & ics of dans of vitamin',\n",
              " 'я не могу.',\n",
              " 'отйда',\n",
              " '- с подвозными?',\n",
              " 'не надо делать, как красные, как это?',\n",
              " 'я и самое главное лечение',\n",
              " '',\n",
              " 'длина ( a ) 218мм',\n",
              " '',\n",
              " 'сара, эмоциональная?',\n",
              " 'это для него для восстановления.',\n",
              " '5.',\n",
              " 'это так, а.',\n",
              " 'с каждым днем.',\n",
              " 'регистрация 41 / 247 /- 66',\n",
              " 'с.',\n",
              " '1. 2. 2. 1. 2. 1.',\n",
              " 'он прикровный по умолчанию',\n",
              " 'transmitted : 12 / 9 / 2017 6 : 57 : 57 am',\n",
              " '- я хочу быть в прошлом.',\n",
              " '- я не могу.',\n",
              " 'в.',\n",
              " 'рекомендация 1170 грн.',\n",
              " 'начало :',\n",
              " 'в праве на образование.',\n",
              " 'и в.',\n",
              " '# 2 павшие защитники 25 ( 00 : 07 : 13 )',\n",
              " 'это до конца.',\n",
              " 'длина#+++++++#++++++++',\n",
              " '',\n",
              " '- да.',\n",
              " 'в.',\n",
              " 'в.',\n",
              " '2 / 2 / rev. 7 в час iv.',\n",
              " 'хорошо, чтобы отпраздновать это.',\n",
              " 'и их, отбирать от аптеки.',\n",
              " 'в.',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ru_sents_test[:10]"
      ],
      "metadata": {
        "id": "pRY7yBESGYxa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82f3557b-13dc-4d3d-d902-f6cf18aaec2d"
      },
      "id": "pRY7yBESGYxa",
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['только бы не вылететь.',\n",
              " 'и как ты только справляешься, папа, таская эти коробки взад-вперед целый день.',\n",
              " 'возможно, у нас есть небольшое преимущество в переговорах.',\n",
              " 'сколько времени вы будете делать то, что ему нужно?',\n",
              " '1 апреля президент нкр бако саакян принял начальника генштаба вооруженных сил республики армения генерал-полковника юрия хачатурова.',\n",
              " 'г-н приснер также упомянул, что система электронного правосудия не только позволила улучшить процесс ведения дел, но также способствует значительному упорядочению процедур.',\n",
              " '- неплохо, да.',\n",
              " 'posted: 15 dec 2006, 00:07',\n",
              " 'и на минутку я подумал, что за ним могут следить.',\n",
              " '«: 11 октябрь 2011, 17:15:34»']"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "tzaCcMRfgUuz"
      },
      "id": "tzaCcMRfgUuz",
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bleus = []\n",
        "\n",
        "for i, t in enumerate(translations):\n",
        "  reference = tokenizer_ru.encode(t).tokens\n",
        "  hypothesis = tokenizer_ru.encode(ru_sents_test[i]).tokens\n",
        "\n",
        "bleus.append(nltk.translate.bleu_score.sentence_bleu([reference], hypothesis,  ))"
      ],
      "metadata": {
        "id": "hx3kUhHQFhMQ"
      },
      "id": "hx3kUhHQFhMQ",
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(sum(bleus)/len(bleus))*100"
      ],
      "metadata": {
        "id": "rJDX-Z-3GKDE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e82c3d1d-2b48-450a-8a0e-3a325acd1575"
      },
      "id": "rJDX-Z-3GKDE",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30.29928206533524"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Задание 2.\n",
        "\n",
        "Прочитайте главу про машинный перевод у Журафски и Маннига - https://web.stanford.edu/~jurafsky/slp3/10.pdf Ответьте своими словами в чем заключается техника back translation? Для чего она применяется и что позволяет получить? Опишите по шагам как его применить к паре en-ru на данных из семинара"
      ],
      "metadata": {
        "id": "s7yQjJCs_FGg"
      },
      "id": "s7yQjJCs_FGg"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Back translation (обратный перевод) - это метод, который помогает увеличить объем данных для перевода, особенно полезный в случае малоресурсных языков.\n",
        "\n",
        "Его суть заключается в использовании модели, которая обучается на параллельных данных для перевода с target языка на source язык. Затем эта модель используется для перевода большого объема текстов на target языке. Полученные данные добавляются к имеющимся данным на source языке, и на этих расширенных данных обучается новая модель для перевода с source языка на target.\n",
        "\n",
        "Этот метод особенно результативен, когда данных на target языке гораздо больше, чем на source языке.\n",
        "\n",
        "Допустим, мы хотим применить этот метод к переводу с немецкого на английский язык. Для этого мы обучаем модель на параллельных данных для перевода с английского на немецкий. Затем применяем эту модель к англоязычным текстам, которых нет в параллельном датасете, и добавляем полученные данные к имеющимся. Наконец, на этих расширенных данных мы обучаем новую модель для перевода с немецкого на английский язык."
      ],
      "metadata": {
        "id": "gUndi8o7JrRD"
      },
      "id": "gUndi8o7JrRD"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}