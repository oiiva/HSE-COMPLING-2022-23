{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9ce6aa68",
      "metadata": {
        "id": "9ce6aa68"
      },
      "source": [
        "# Задание 1.\n",
        "\n",
        "Проанализируйте текст ниже с помощью майстема. Уберите из получившегося списка элементы, у которых нет грамматического разбора. Для каждего из оставшихся токенов выберите самый вероятный грамматический разбор. Из каждого разбора выберите только тег части речи (тэг должен состоять только из латинских букв). Найдите три самых частотных тега во всем тексте. Совместите эти три тега в одну строку (разделитель - пробел). Итоговую строку вставьте в форму для экзамена.\n",
        "\n",
        "*Пример: для такого разбора \"PR=\" частеречный тэг - \"PR\", а для такого \"S,муж,неод=твор,ед\" - \"S\" *"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymorphy2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6vs46S0lGn0",
        "outputId": "004ef338-eaa1-491e-eff4-4567410d8b1c"
      },
      "id": "f6vs46S0lGn0",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pymorphy2\n",
            "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dawg-python>=0.7.1 (from pymorphy2)\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4 (from pymorphy2)\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docopt>=0.6 (from pymorphy2)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: docopt\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13707 sha256=b8ffd6bfcd5125b767941dd791d1a438e9e168fcf19b5a52aee87bc149191d1a\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built docopt\n",
            "Installing collected packages: pymorphy2-dicts-ru, docopt, dawg-python, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 docopt-0.6.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pymorphy2"
      ],
      "metadata": {
        "id": "sJHjnTVbk9C7"
      },
      "id": "sJHjnTVbk9C7",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "54488642",
      "metadata": {
        "id": "54488642"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"\n",
        "В сетевом фольклоре есть такой жанр — пересказ научных экспериментов.\n",
        "Чтобы исследование стало вирусным, его предметом непременно должны быть социальные отношения — то есть участвуют или люди, или животные, которых легко проассоциировать с людьми, — а результат обязательно призван иллюстрировать «естественную» для человека порочность.\n",
        "Вы наверняка читали истории о несчастных обезьянах, которых отучали брать банан с помощью холодной воды, или о «мышином рае», чьи обитатели вымерли от якобы слишком комфортной жизни.\n",
        "Проблема таких рассказов в том, что они, как правило, слабо связаны с работой реальных ученых: эксперименты либо вызывали жесткую критику в научной среде, либо вообще никогда не проводились.\n",
        "\n",
        "Эти мемы эксплуатируют авторитет науки, но не меняют и не уточняют представления публики о человеке и обществе, а просто подтверждают уже существующие у нее взгляды: скажем, что люди от природы склонны к насилию или подчинению.\n",
        "Отсюда — их популярность: приятно осознавать, что, например, ваша мизантропия оказалась не беспочвенна. По сути, перед нами суррогат критического мышления: оголтелому позитиву массовой культуры противопоставлен такой же оголтелый негатив.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "c4a84424",
      "metadata": {
        "id": "c4a84424"
      },
      "outputs": [],
      "source": [
        "morph = pymorphy2.MorphAnalyzer()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = text.split()"
      ],
      "metadata": {
        "id": "IYRoUGYJlf-r"
      },
      "id": "IYRoUGYJlf-r",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxTWZ_onlkS2",
        "outputId": "9ff78f2b-4ee9-424c-a20d-347b388b2e26"
      },
      "id": "WxTWZ_onlkS2",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['В', 'сетевом', 'фольклоре', 'есть', 'такой', 'жанр', '—', 'пересказ', 'научных', 'экспериментов.', 'Чтобы', 'исследование', 'стало', 'вирусным,', 'его', 'предметом', 'непременно', 'должны', 'быть', 'социальные', 'отношения', '—', 'то', 'есть', 'участвуют', 'или', 'люди,', 'или', 'животные,', 'которых', 'легко', 'проассоциировать', 'с', 'людьми,', '—', 'а', 'результат', 'обязательно', 'призван', 'иллюстрировать', '«естественную»', 'для', 'человека', 'порочность.', 'Вы', 'наверняка', 'читали', 'истории', 'о', 'несчастных', 'обезьянах,', 'которых', 'отучали', 'брать', 'банан', 'с', 'помощью', 'холодной', 'воды,', 'или', 'о', '«мышином', 'рае»,', 'чьи', 'обитатели', 'вымерли', 'от', 'якобы', 'слишком', 'комфортной', 'жизни.', 'Проблема', 'таких', 'рассказов', 'в', 'том,', 'что', 'они,', 'как', 'правило,', 'слабо', 'связаны', 'с', 'работой', 'реальных', 'ученых:', 'эксперименты', 'либо', 'вызывали', 'жесткую', 'критику', 'в', 'научной', 'среде,', 'либо', 'вообще', 'никогда', 'не', 'проводились.', 'Эти', 'мемы', 'эксплуатируют', 'авторитет', 'науки,', 'но', 'не', 'меняют', 'и', 'не', 'уточняют', 'представления', 'публики', 'о', 'человеке', 'и', 'обществе,', 'а', 'просто', 'подтверждают', 'уже', 'существующие', 'у', 'нее', 'взгляды:', 'скажем,', 'что', 'люди', 'от', 'природы', 'склонны', 'к', 'насилию', 'или', 'подчинению.', 'Отсюда', '—', 'их', 'популярность:', 'приятно', 'осознавать,', 'что,', 'например,', 'ваша', 'мизантропия', 'оказалась', 'не', 'беспочвенна.', 'По', 'сути,', 'перед', 'нами', 'суррогат', 'критического', 'мышления:', 'оголтелому', 'позитиву', 'массовой', 'культуры', 'противопоставлен', 'такой', 'же', 'оголтелый', 'негатив.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter"
      ],
      "metadata": {
        "id": "nH5m1tqancN1"
      },
      "id": "nH5m1tqancN1",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tags= []\n",
        "\n",
        "for token in tokens:\n",
        "    parsed = morph.parse(token)\n",
        "    if parsed:\n",
        "        lemma = parsed[0].normal_form\n",
        "        tag = parsed[0].tag.POS\n",
        "        if tag is not None:\n",
        "            tags.append(tag)"
      ],
      "metadata": {
        "id": "qHG9PgvtoXii"
      },
      "id": "qHG9PgvtoXii",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "d794221b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d794221b",
        "outputId": "925cdde0-5191-45f2-ba2e-0abf602a0de0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOUN ADJF CONJ\n"
          ]
        }
      ],
      "source": [
        "tag_counts = Counter(tags)\n",
        "top_3_tags = [tag for tag, count in tag_counts.most_common(3)]\n",
        "\n",
        "result = \" \".join(top_3_tags)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8492784",
      "metadata": {
        "id": "b8492784"
      },
      "source": [
        "## Задание 2\n",
        "\n",
        "Вам дана последовательность правильных ответов для задачи бинарной классификации. Используя эти правильные ответы, рассчитайте accuracy модели, которая будет предсказывать только положительный класс. Округлите значение до 2 знаков после запятой. Вставьте число в форму."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "id": "d41953d5",
      "metadata": {
        "id": "d41953d5"
      },
      "outputs": [],
      "source": [
        "binary_true = [1,1,1,1,0,1,0,1,0,1,0,1,1,1,1,1,1,1,0,0,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "d3d7fe16",
      "metadata": {
        "id": "d3d7fe16"
      },
      "outputs": [],
      "source": [
        "positive_predictions = [1] * len(binary_true)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct_predictions = sum([1 for true, pred in zip(binary_true, positive_predictions) if true == pred])"
      ],
      "metadata": {
        "id": "HuKQtT-bqt8T"
      },
      "id": "HuKQtT-bqt8T",
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = correct_predictions / len(binary_true)\n",
        "\n",
        "rounded_accuracy = round(accuracy, 2)\n",
        "print(rounded_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tB2kQXQOqzPc",
        "outputId": "e394c174-1f30-410e-a86c-ff41eb36f823"
      },
      "id": "tB2kQXQOqzPc",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.67\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ede26498",
      "metadata": {
        "id": "ede26498"
      },
      "source": [
        "## Задание 3.\n",
        "\n",
        "Вам дана последовательность с правильными ответами для задачи многоклассовой классификации. А также массив с предсказаниями такой же длины, но в виде вероятностей для каждого класса. Для каждой строчки выберите самый вероятный класс. Сравните полученные метки классов с правильными ответами с помощью f1-меры с макро усреднением по классам. Округлите полученную метрику до 2 знака после запятой и вставьте в форму для экзамена в соответствующее поле."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "id": "f350110f",
      "metadata": {
        "id": "f350110f"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "id": "ef070800",
      "metadata": {
        "id": "ef070800"
      },
      "outputs": [],
      "source": [
        "multiclass_true = [0,3,0,0,3,0,0,1,2,4,1,2,4,0,2,0,4,1,2,4,1,1,4,1,2,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "id": "bb7f465b",
      "metadata": {
        "id": "bb7f465b"
      },
      "outputs": [],
      "source": [
        "probas = np.array([[0.14283307, 0.69125398, 0.08801677, 0.05890497, 0.01899121],\n",
        "       [0.05017326, 0.16837714, 0.09787715, 0.37586925, 0.3077032 ],\n",
        "       [0.07349622, 0.20737874, 0.06666821, 0.0582571 , 0.59419973],\n",
        "       [0.08704361, 0.18970222, 0.16262277, 0.08630088, 0.47433053],\n",
        "       [0.16137361, 0.21450292, 0.22870402, 0.24422044, 0.151199  ],\n",
        "       [0.268094  , 0.43761478, 0.12385365, 0.04917541, 0.12126215],\n",
        "       [0.27161954, 0.01412896, 0.11056462, 0.09468905, 0.50899783],\n",
        "       [0.09363269, 0.02693918, 0.33977914, 0.39909705, 0.14055195],\n",
        "       [0.29520778, 0.05132426, 0.06673668, 0.45254433, 0.13418695],\n",
        "       [0.15421375, 0.22964685, 0.16662999, 0.21004033, 0.23946907],\n",
        "       [0.24755032, 0.24628846, 0.12956078, 0.24832473, 0.12827571],\n",
        "       [0.11797719, 0.03232272, 0.07293219, 0.52455883, 0.25220907],\n",
        "       [0.75835945, 0.07189134, 0.06032446, 0.04986686, 0.05955789],\n",
        "       [0.02601848, 0.26673495, 0.03124844, 0.21992134, 0.4560768 ],\n",
        "       [0.58059452, 0.03148405, 0.11400383, 0.14452069, 0.12939691],\n",
        "       [0.08215579, 0.32887402, 0.10776154, 0.30880314, 0.17240552],\n",
        "       [0.11467395, 0.07250172, 0.03868279, 0.04358503, 0.73055651],\n",
        "       [0.09546111, 0.22318028, 0.04797582, 0.42230537, 0.21107742],\n",
        "       [0.17088269, 0.31617363, 0.02329777, 0.26480448, 0.22484143],\n",
        "       [0.1573525 , 0.04416687, 0.59056588, 0.0854817 , 0.12243306],\n",
        "       [0.16300152, 0.224168  , 0.11143585, 0.09995103, 0.4014436 ],\n",
        "       [0.17649215, 0.32146966, 0.21575183, 0.0238604 , 0.26242596],\n",
        "       [0.00860468, 0.01201256, 0.96059244, 0.00327634, 0.01551398],\n",
        "       [0.06455855, 0.11772163, 0.25971348, 0.32510222, 0.23290411],\n",
        "       [0.04150647, 0.1329052 , 0.22146507, 0.03930956, 0.5648137 ],\n",
        "       [0.12671909, 0.01486602, 0.77637796, 0.06239952, 0.01963741]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "id": "1f253639",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f253639",
        "outputId": "d4d46e46-6381-4b86-c93e-25e38c7794bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 3, 4, 4, 3, 1, 4, 3, 3, 4, 3, 3, 0, 4, 0, 1, 4, 3, 1, 2, 4, 1,\n",
              "       2, 3, 4, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "predicted_classes = np.argmax(probas, axis=1)\n",
        "\n",
        "predicted_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "id": "0a0fda55",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a0fda55",
        "outputId": "768f4298-8019-441f-f4d5-86cd2f94a60e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.18\n"
          ]
        }
      ],
      "source": [
        "f1_macro = f1_score(multiclass_true, predicted_classes, average='macro')\n",
        "\n",
        "rounded_f1_macro = round(f1_macro, 2)\n",
        "print(rounded_f1_macro)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3dd46798",
      "metadata": {
        "id": "3dd46798"
      },
      "source": [
        "## Задание 4\n",
        "\n",
        "Загрузите токенизатор и модель 'distilbert-base-multilingual-cased'. Токенизируйте и рассчитайте векторные представления для двух приведенных ниже текстов. Усредните векторные представления токенов каждого из текстов так, чтобы для каждого из текстов получился вектор размером 768.\n",
        "Рассчитайте косинусную близость между двумя этим векторами, округлите её до 2 знака после запятой и вставьте число в форму."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "Wc7H3KtySBFZ"
      },
      "execution_count": 77,
      "outputs": [],
      "id": "Wc7H3KtySBFZ"
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpTI6LhKSmye",
        "outputId": "178aa569-817b-4d91-98d5-3519a0ecf954"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ],
      "id": "WpTI6LhKSmye"
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYaS3pn4S_d4",
        "outputId": "5eb55264-8934-4c39-a99e-2c36646f40ad"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "id": "IYaS3pn4S_d4"
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DistilBertTokenizer, DistilBertModel\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import torch"
      ],
      "metadata": {
        "id": "G0t9VQy9TRRJ"
      },
      "execution_count": 80,
      "outputs": [],
      "id": "G0t9VQy9TRRJ"
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-multilingual-cased')\n",
        "model = DistilBertModel.from_pretrained('distilbert-base-multilingual-cased')\n",
        "\n",
        "\n",
        "text1 = \"Колибри не понравился сироп с повышенным содержанием спирта\"\n",
        "text2 = \"Подопытные колибри пили из всех предложенных кормушек.\"\n",
        "\n",
        "\n",
        "tokens1 = tokenizer.encode(text1, add_special_tokens=True)\n",
        "tokens2 = tokenizer.encode(text2, add_special_tokens=True)\n",
        "\n",
        "\n",
        "input_ids1 = torch.tensor([tokens1])\n",
        "input_ids2 = torch.tensor([tokens2])\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs1 = model(input_ids1)\n",
        "    outputs2 = model(input_ids2)\n",
        "\n",
        "\n",
        "mean_embedding1 = torch.mean(outputs1[0], dim=1).squeeze(0)\n",
        "mean_embedding2 = torch.mean(outputs2[0], dim=1).squeeze(0)\n",
        "\n",
        "\n",
        "cos_sim = cosine_similarity(mean_embedding1.reshape(1, -1), mean_embedding2.reshape(1, -1))\n",
        "\n",
        "rounded_cos_sim = round(cos_sim[0][0], 2)\n",
        "print(rounded_cos_sim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXXtY7myxOoM",
        "outputId": "97ec3ed1-7e70-41b1-863b-04f2fc9f7c8a"
      },
      "id": "HXXtY7myxOoM",
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-multilingual-cased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_transform.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.77\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b4fb936",
      "metadata": {
        "id": "4b4fb936"
      },
      "source": [
        "# Задание 5"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5af1adfb",
      "metadata": {
        "id": "5af1adfb"
      },
      "source": [
        "Используя модель \"EleutherAI/gpt-neo-125m\" (huggingface), сгенерируйте продолжение следующего текста:\n",
        "\"The exam was\".\n",
        "\n",
        "Используйте следующее параметры при генерации: минимальная длина продолжения - 20 токенов, максимальная длина продолжения - 48 токенов, отсутствие повторов длиной 2 токена, отсутствие семплирования (выбирается только самый вероятный токен).\n",
        "\n",
        "Вставьте полученный текст (изначальный текст + сгенерированное продолжение) в форму целиком (кавычки лучше не включать, но сработает и с ними)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "248-mCxSTmz2",
        "outputId": "edba6b59-cd1a-465b-a435-da6cda2c3cbc"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.20.3-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.6/227.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.20.3\n"
          ]
        }
      ],
      "id": "248-mCxSTmz2"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOedQYSNT6-v",
        "outputId": "653c1dfa-17a3-4463-bfb5-589147429911"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ],
      "id": "HOedQYSNT6-v"
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPTNeoForCausalLM, AutoTokenizer\n",
        "\n",
        "model_name = \"EleutherAI/gpt-neo-125m\"\n",
        "\n",
        "\n",
        "model = GPTNeoForCausalLM.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "min_length = 20\n",
        "max_length = 48\n",
        "no_repeat_ngram_size = 2\n",
        "do_sample = False\n",
        "\n",
        "input_text = \"The exam was\"\n",
        "\n",
        "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
        "\n",
        "output = model.generate(\n",
        "    input_ids,\n",
        "    min_length=min_length,\n",
        "    max_length=max_length,\n",
        "    no_repeat_ngram_size=no_repeat_ngram_size,\n",
        "    do_sample=do_sample,\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        ")\n",
        "\n",
        "\n",
        "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R26XTC3oTnOf",
        "outputId": "149134da-3e51-43a5-f4d2-aa1c8cc364ca"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The exam was held at the University of California, Berkeley, and the students were asked to complete the exam. The exam questions were written in English and Spanish.\n",
            "\n",
            "The students who were not able to finish the test were given a certificate\n"
          ]
        }
      ],
      "id": "R26XTC3oTnOf"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}